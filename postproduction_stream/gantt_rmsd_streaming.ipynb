{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_md = 120\n",
    "n_ml = 1\n",
    "n_aggregators = 10\n",
    "fn = glob.glob(\"re.session*.csv\")[0]\n",
    "#fn1 = f'pf{n_md}{ex}.csv'\n",
    "sdir = f'./'\n",
    "print(fn,sdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists('pfd.pickle')):\n",
    "    print(\"Skip the next two cells, they take forever\")\n",
    "    with open('pfd.pickle','rb') as f:\n",
    "        pfd = pickle.load(f)\n",
    "    pfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfu = {}\n",
    "pfd = {}\n",
    "\n",
    "for u in pf['unit'].unique():\n",
    "    #print(f'u={u}')\n",
    "    tmp = pf[pf.unit == u].reset_index()\n",
    "    pfu[u] = {}\n",
    "    pfd[u] = {}\n",
    "    for l in tmp.label.unique():\n",
    "        pfu[u][l] = tmp[tmp.label == l].reset_index()\n",
    "        \n",
    "        starts = []\n",
    "        ends = []\n",
    "        durations = []\n",
    "        \n",
    "        starts1 = []\n",
    "        ends1 = []\n",
    "        durations1 = []\n",
    "\n",
    "        units = []\n",
    "        labels = []\n",
    "        times = []\n",
    "        \n",
    "        for i in range(0,len(pfu[u][l])//2*2 - 2,2):\n",
    "            start = pfu[u][l].gps[i]\n",
    "            end = pfu[u][l].gps[i+1]\n",
    "            start1 = pfu[u][l].time[i]\n",
    "            end1 = pfu[u][l].time[i+1]\n",
    "            duration = end - start\n",
    "            duration1 = end1 - start1\n",
    "            unit = pfu[u][l].unit[i]\n",
    "            label = pfu[u][l].label[i]\n",
    "            starts.append(start)\n",
    "            ends.append(end)\n",
    "            durations.append(duration)\n",
    "            starts1.append(start1)\n",
    "            ends1.append(end1)\n",
    "            durations1.append(duration1)\n",
    "            units.append(unit)\n",
    "            labels.append(label)\n",
    "        pfd[u][l] = pd.DataFrame(columns=[\"start\",\"end\",\"duration\",\"start1\",\"end1\",\"duration1\", \"unit\",\"label\"])\n",
    "        pfd[u][l].start = starts\n",
    "        pfd[u][l].end = ends\n",
    "        pfd[u][l].duration = durations\n",
    "        pfd[u][l].start1 = starts1\n",
    "        pfd[u][l].end1 = ends1\n",
    "        pfd[u][l].duration1 = durations1        \n",
    "        pfd[u][l].unit = units\n",
    "        pfd[u][l].label = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfu[131].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfu[130].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pfd.pickle', 'wb') as f:\n",
    "    pickle.dump(pfd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 32})\n",
    "\n",
    "nnn=n_md\n",
    "offset=0\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "fig, gnt = plt.subplots(figsize=(15, 6)) \n",
    "#ddd = 4 #-4.5\n",
    "#gnt.text(ddd,7,'outlier search')\n",
    "#gnt.text(ddd,5,'machine learning')\n",
    "#gnt.text(ddd,3,'aggregation')\n",
    "#gnt.text(ddd,1,'simulation')\n",
    "gnt.get_yaxis().set_visible(False)\n",
    "\n",
    "gnt.set_xlabel('Elapsed time since start, hours') \n",
    "# gnt.set_ylabel('task')\n",
    "\n",
    "gnt.set_ylim([0, 8])\n",
    "\n",
    "#gnt.grid(True)\n",
    "\n",
    "pfd[0+offset]['molecular_dynamics_step'].start\n",
    "\n",
    "sh = 0\n",
    "h=1\n",
    "\n",
    "\n",
    "for i in range(offset,offset+1):\n",
    "    z = pfd[i]['molecular_dynamics_step']\n",
    "    zz = list(zip((z.start - z.start.min())/3600, z.duration/3600))\n",
    "\n",
    "    zz1 = zz[0:len(zz):2]\n",
    "    gnt.broken_barh(zz1, (sh, h), facecolors =('tab:orange'), label=\"simulation\")\n",
    "\n",
    "    sh += h    \n",
    "    \n",
    "    zz1 = zz[1:len(zz):2]\n",
    "    gnt.broken_barh(zz1, (sh, h), facecolors =('tab:orange'))\n",
    "\n",
    "    sh += h    \n",
    "for i in range(1):\n",
    "    z = pfd[n_md+i+offset]['aggregator_iteration']\n",
    "    zz = list(zip((z.start - z.start.min())/3600, z.duration/3600))\n",
    "\n",
    "    zz1 = zz[0:len(zz):2]\n",
    "    gnt.broken_barh(zz1, (sh, h), facecolors ='tab:blue', label=\"aggregation\")\n",
    "\n",
    "    sh += h\n",
    "\n",
    "    zz1 = zz[1:len(zz):2]\n",
    "    gnt.broken_barh(zz1, (sh, h), facecolors ='tab:blue')\n",
    "\n",
    "    sh += h\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    z = pfd[n_md+n_aggregators+i+offset]['ml_iteration']\n",
    "    zz = list(zip((z.start - z.start.min())/3600, z.duration/3600))\n",
    "\n",
    "    zz1 = zz[0:len(zz):2]\n",
    "    gnt.broken_barh(zz1, (sh, h), facecolors ='tab:red', label=\"CVAE training\")\n",
    "\n",
    "    sh += h\n",
    "\n",
    "    zz1 = zz[1:len(zz):2]\n",
    "    gnt.broken_barh(zz1, (sh, h), facecolors ='tab:red')\n",
    "\n",
    "    sh += h\n",
    "\n",
    "z = pfd[n_md + n_aggregators + n_ml +offset]['outlier_search_iteration']\n",
    "zz = list(zip((z.start - z.start.min())/3600, z.duration/3600))\n",
    "\n",
    "zz1 = zz[0:len(zz):2]\n",
    "gnt.broken_barh(zz1, (sh, h), facecolors ='tab:green', label=\"outlier search\")\n",
    "\n",
    "sh += h\n",
    "\n",
    "zz1 = zz[1:len(zz):2]\n",
    "gnt.broken_barh(zz1, (sh, h), facecolors ='tab:green')\n",
    "\n",
    "#gnt.legend()\n",
    "\n",
    "plt.savefig(\"gantt2.png\", dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
