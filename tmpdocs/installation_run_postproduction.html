<html>
  <body>
    <h1>How to use DDMD-S on lassen@LLNL with the existing installation of dependencies</h1>
    <h2>Run</h2>
    <ul>
      <li>Set up the environment:</br><br>
	module load gcc/7.3.1<br>
	. /etc/profile.d/conda.sh<br>
	conda activate /usr/workspace/cv_ddmd/conda1/powerai<br>
	export IBM_POWERAI_LICENSE_ACCEPT=yes<br>
	module use /usr/workspace/cv_ddmd/software1/modules<br>
	module load adios2<br><br>

	(Usuall I source something like <a href="powerai3.sh">this</a> to do this)<br><br>

      <li>Download DDMD from github:<br><br>
	mkdir /usr/workspace/cv_ddmd/$USER<br>
	cd /usr/workspace/cv_ddmd/$USER<br>
	git clone git@github.com:DeepDriveMD/DeepDriveMD-pipeline.git<br><br>
      <li>For convenience, let us define:<br><br>
	export DDMD="/usr/workspace/cv_ddmd/$USER/DeepDriveMD-pipeline"<br>
	alias cdddmd="cd $DDMD"<br><br>
      <li>To run various preconfigured examples:<br><br>
	cd $DDMD/test<br>
	nohup make X > X.log 2>&1 &<br><br>
	where X is one of these<br><br>
	<ul>
	  <li>run1 - mini BBA run with 12 simulations, 1 aggregator; 30m.
	  <li>run2 - production BBA run with 120 simulations, 10 aggregators; 12h.
	  <li>run3 - production BBA run, no outliers, no machine learning is used, states for the next batch of the simulations are selected randomly from the reported states; 120 simulations, 10 aggregators; 12h.
	  <li>run3m - same as run3, but 12 simulations, 1 aggregator; 30m.
	  <li>run4 - production BBA run, random selection of outliers; 120 simulations, 10 aggregators; 12h.
	  <li>run4m - same as run4 by 12 simulations, 1 aggregator; 30m.
	  <li>run5 - production BBA run, greedy selection from the traversed states based on RMSD, no outliers are used; 120 simulations, 10 aggregators; 12h.
	  <li>run5m - same as run5 but 12 simulations, 1 aggregator; 30m.
	  <li>run6 - same as run9 but 12 simulations, 1 aggregator; 3h.
	  <li>run6a - same as run9a but 12 simulations, 1 aggregator, 3h.
	  <li>run7 - production run for insRec_OM_region; 120 simulations, 10 aggregators; 12h.
	  <li>run7m - same as run7 but 12 simulations, 1 aggregator; 4h.
	  <li>run8 - production run for spike; 120 simulations, 10 aggregators; 12h.
	  <li>run9 - production run for smoothended_rec, 120 simulations, 10 aggregators; 12h.
	  <li>run9a - production run for smoothended_rec where CVAE is replaced by AAE; 120 simulations, 10 aggregators; 12h.
	  <li>run10 - same as run11 but 12 simulations, 1 aggregator; 6h.
	  <li>run11 - production run for multi-ligand case; 120 simulations, 10 aggregators; 12h.
	</ul><br>
      <li>The configuration files for the above cases can be found by appending $DDMD with test/bba/DIR where DIR is listed in the Makefile. For example, for run1, the path is $DDMD/test/bba/test1_stream.<br>
      <li>The main configuration file is generate.py that is edited to generate a yaml file:<br>
	python generate.py > config.yaml<br>
      <li>adios_file.xml controls the output of a complete trajectory including positions, velocities, contact maps from each simulation.<br>
      <li>adios_sim.xml controls the communication over the network between a simulation and an aggregator.<br>
      <li>adios_agg_4ml.xml controls the communication over the network between an aggregator a machine learning.<br>
      <li>adios_agg.xml controls the communication over the network between an aggregator and an outlier search.<br>
      <li>Notice that bin/run.sh command sets up authorization in this line<br>
	source /usr/workspace/cv_ddmd/.radical/auth<br>
	For the content of this file for a particular cluster, ask Radical developers. In this file various environmental variables are set, such as RMQ_HOSTNAME, RMQ_PASSWORD, ..., mongodb_host, ..., RADICAL_PILOT_DBURL, ...,  that allow Radical Ensemble Toolkit to
	communicate with the corresponding servers.
    </ul>

    <h1>Results</h1>
    <ul>
      <li>Radical logs: /p/gpfs1/$USER/radical.pilot.sandbox
      <li>The latest best model: {experiment_directory}/machine_learning_runs/stage0000/task0000/published_model/best.h5, where {experiment_directory} is specified in generate.py (and in the corresponding config.yaml)
      <li>ADIOS trajectories from each simulation invocation: {experiment_directory}/molecular_dynamics_runs/stage0000/task*/*/trajectory.bp
	<ul>
	  <li>There is only one stage and as many tasks under molecular_dynamics_runs/stage0000 directory as there are parallel simulations (in our typical production run we use 120 parallel simulations, in mini test runs - 12 simulations).
	  <li>Under each taskXXXX directory, there are subdirectories 0, 1, ... corresponding to different restarts of the simulations from the outliers.
	  <li>The first one or two simulations are started from initial conditions. For the rest, the corresponding outlier files are copied
	</ul>
    </ul>
    

    <h1>Postproduction</h1>

    <h2>Trajectories</h2>
    <ul>
      <li>Trajectories in bp format are saved for each simulation. For example:<br>
$ bpls /p/gpfs1/yakushin/Outputs/3/molecular_dynamics_runs/stage0000/task0000/4/trajectory.bp<br>
  char     contact_map  100*{28, 28}<br>
  int32_t  gpstime      100*{1}<br>
  int64_t  md5          100*{32}<br>
  float    positions    100*{504, 3}<br>
  float    rmsd         100*{1}<br>
  int32_t  step         100*{1}<br>
	float    velocities   100*{504, 3}<br>
      <li>The above output says that there are 100 time steps saved in trajectory.bp. For each time step, we save 28x28 contact map, gpftime when the time step was reported, md5 sum of positions, positions (in this case, it is x,y,z coordinates for each of the 504 atoms, corresponding
	velocities, rmsd to the folded state, reporting step in the simulation (here it is from 0 to 99).
      <li>To convert those trajectories into npy format, using 4 nodes, 10-minute walltime, do:<br>
	<ul>
	  <li>cd $DDMD/postproduction
	  <li>nohup ./run_positions.py 3 4 10 > positions_3.log 2>&1 &
	  <li>Here 3 corresponds to the output directory for the run: /p/gpfs1/yakushin/Outputs/3
	  <li>Running the above command creates positions.npy in each directory where trajectory.bp is found
	  <li>The script uses Radical-ENTK to create as many independent tasks (that can run in parallel) as there are trajectories.
	  <li>You might have to edit driver_positions.py to change the path to your python and to your $DDMD, your file that sets the environment for the jobs.
	</ul>
    </ul>
    <h2>Loss curves</h2>
    <ul>
      <li>python loss_real1.py -s re.session.lassen709.yakushin.019150.0009 -p 0 -t 13<br>
	provided that the log file for the machine learning task is in /p/gpfs1/yakushin/radical.pilot.sandbox/re.session.lassen709.yakushin.019150.0009/pilot.0000/task.0013/task.0013.out
	<ul>
	  <li>The corresponding *.csv file will be in /p/gpfs1/yakushin/Outputs/3/postproduction/losses.csv
	  <li>The loss curves can be plotted by with $DDMD/postproduction/loss.ipynb
	</ul>
      <li>For AAE case, the logs are written in a different format and can be parsed with
	<ul>
	  <li>python loss_aae.py logfile dir<br>
		where dir is subdirectory of /p/gpfs1/yakushin/Outputs where the run files are written.
	</ul>
    </ul>
    <h2>Gantt charts</h2>
    <ul>
      <li>To parse log files in order to generate gantt charts, run from postproduction directory:<br>
	nohup ./run_timers.sh output_dir nodes walltime session pilot exclude > timers.log 2>&1 &<br>
	where output_dir - subdirectory of /p/gpfs1/yakushin/Outputs, nodes - number of nodes to use (the job is submitted to the cluster),
	walltime - maximum walltime, session - log session like re.session.lassen709.yakushin.019150.0009, pilot - typically 0, exclude - what tasks to exclude (for example, it is not interesting to see timing
	for aggregators and it takes a lot of time to parse the corresponding logs so you can exclude those by using 120-129 as exclude (currently it is dumb and just parses one range)
      <li>An example of the notebook to plot gantt charts: postproduction/gantt_rmsd_streaming.ipynb
    </ul>
    <h2>Embeddings</h2>
    <ul>
      <li>To generate embedding files, run from the postproduction directory:<br>
      nohup ./run_emb.sh > emb.log outputdir nodes walltime zcentroid 2>&1 &<br>
      where outputdir - subdirectory of /p/gpfs1/yakushin/Outputs/ where job outputs are stored, nodes - number of nodes to use (the job is submitted to the cluster), walltime - up to how much time to run the job, zcentroid - 1 or 0
      depending on whether you want to calculate zcentroid or not.
      <li>An example notebook to plot embeddings: postproduction/plot_tsne.ipynb
    </ul>
	
    <h1>How to install software dependencies for DDMD-S on lassen</h1>

    <ul>
      <li>Set up the environment for Anaconda:<br>
	module load gcc/7.3.1<br>
	. /etc/profile.d/conda.sh<br>
	export IBM_POWERAI_LICENSE_ACCEPT=yes
      <li>Follow IBM's documentation to install powerai environment (https://www.ibm.com/docs/en/wmlce/1.7.0?topic=installing-mldl-frameworks) with some modifications:<br><br>
	conda config --prepend channels https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/<br>
	export CONDA2=/usr/workspace/cv_ddmd/conda2<br>
	mkdir $CONDA2<br><br>

	Add the following lines to $HOME/.condarc so that the packages are downloaded not into $HOME but into $CONDA2:<br><br>

	pkgs_dirs:<br>
	   - /usr/workspace/cv_ddmd/conda2/pkgs<br><br>

	conda create -p $CONDA2/powerai<br>
	conda activate /usr/workspace/cv_ddmd/conda2/powerai<br>
	conda install powerai - this step can easily take several hours before it even prompts you to answer '[y]/n'<br>
	conda install powerai-rapids

      <li>Install adios:
	<ul>
	  <li>git clone git@github.com:ornladios/ADIOS2.git
	  <li>cd ADIOS2
	  <li>mkdir build; cd build
	  <li>cmake -DADIOS2_USE_MPI=OFF -DADIOS2_USE_CUDA=OFF -DCMAKE_INSTALL_PREFIX=/usr/workspace/cv_ddmd/software1/ADIOS2_060522  ..
	  <li>make -j20
	  <li>make install
	  <li>export PYTHONPATH=/usr/workspace/cv_ddmd/software1/ADIOS2_060522/lib/python3.7/site-packages:$PYTHONPATH
	  <li>export PATH=/usr/workspace/cv_ddmd/software1/ADIOS2_060522/bin:$PATH
	  <li>export LD_LIBRARY_PATH=/usr/workspace/cv_ddmd/software1/ADIOS2_060522/lib64:$LD_LIBRARY_PATH
	</ul>
      <li>Assuming that you have configured <a href="https://spack.io/">spack</a>, install swig:
	<ul>
	  <li>spack install swig
	</ul>
      <li>Install openmm:
	<ul>
	  <li>module load cuda/10.2.89
	  <li>module load cmake/3.23.1
	  <li>spack load swig
	  <li>git clone https://github.com/pandegroup/openmm.git
	  <li>cd openmm
	  <li>mkdir build; cd build
	  <li>cmake -DCMAKE_INSTALL_PREFIX=/usr/workspace/cv_ddmd/software1/OPENMM_060522 -DSWIG_EXECUTABLE=`which swig` ..
	  <li>make -j20
	  <li>make install
	  <li>make PythonInstall
	  <li>Test: python -m openmm.testInstallation
	</ul>
      <li>pip install parmed
      <li>pip install pathos
      <li>pip install mdanalysis==1.0.0
      <li>pip install opentsne
      <li>pip install radical.entk==1.6.7 radical.gtod==1.6.7 radical.pilot==1.6.7 radical.saga==1.6.10 radical.utils==1.6.7 (I had trouble with the newest versions on lassen)
      <li>Install mdlearn:
	<ul>
	  <li>git clone https://github.com/ramanathanlab/mdlearn
	  <li>cd mdlearn
	  <li>git checkout develop
	  <li>pip install -e .
	</ul>
      <li>Install MD-Tools:
	<ul>
	  <li>git clone git@github.com:braceal/MD-tools.git
	  <li>cd MD-tools
	  <li>git checkout update/openmm-7.7
	  <li>pip install -e .
	</ul>
      <li>Install DeepDriveMD:
	<ul>
	  <li>git clone git@github.com:DeepDriveMD/DeepDriveMD-pipeline.git
	  <li>cd DeepDriveMD-pipeline
	  <li>git checkout develop
	  <li>Comment numpy,h5py lines in setup.cfg
	  <li>pip install -e .
	</ul>
      <li>Restore broken opencv (which package broke it?):<br>
	conda install -c https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda opencv=3.4.8
      <li>pip install torchsummary
      <li>You might need to modify the corresponding generate.py files for your path and rerun it: python generate.py > config.yaml. While running generate.py script, you need to be in the environment of the program
	since a lot of things, like python path, is picked up from the environment.
  </body>

</html>
